<p align="center">
  <img src="figures/model_comparison.png" alt="Comparaison des performances des modÃ¨les" width="700"/>
</p>
# ğŸŒ Classification de la stabilitÃ© des terrains â€” Machine Learning Project

## ğŸ“Œ PrÃ©sentation
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™un mini-projet acadÃ©mique en **Apprentissage SupervisÃ©**.  
Lâ€™objectif est de construire un systÃ¨me de classification capable de prÃ©dire le **niveau de stabilitÃ© dâ€™un terrain** afin dâ€™identifier les zones Ã  risque de glissement.

Ce problÃ¨me relÃ¨ve dâ€™une tÃ¢che de **classification multiclasse** avec trois catÃ©gories :
- Stable
- Moyennement stable
- Instable

---

## ğŸ¯ Objectifs
Le projet vise Ã  mettre en Å“uvre un pipeline complet de Machine Learning :

- ComprÃ©hension et analyse du dataset
- PrÃ©traitement et nettoyage des donnÃ©es
- Visualisation et analyse exploratoire (EDA)
- EntraÃ®nement de plusieurs modÃ¨les de classification
- Optimisation des hyperparamÃ¨tres
- Ã‰valuation comparative des performances
- InterprÃ©tation des rÃ©sultats

---

## ğŸ“Š DonnÃ©es utilisÃ©es
Le dataset contient des variables gÃ©otechniques et environnementales dÃ©crivant chaque zone :

**Variables explicatives**
- pente_pct â€” pente du terrain
- altitude_m â€” altitude
- texture_sol â€” texture du sol
- humidite_sol â€” humiditÃ©
- distance_faille_km â€” distance aux failles
- couverture_vegetale â€” couverture vÃ©gÃ©tale
- indice_geotech_labo â€” indice gÃ©otechnique

**Variables spatiales (non utilisÃ©es pour lâ€™entraÃ®nement)**
- latitude
- longitude
- zone_id

**Variable cible**
- stabilite_terrain

---

## âš™ï¸ MÃ©thodologie

### 1 â€” Analyse exploratoire
- Distribution des variables
- DÃ©tection des anomalies
- Analyse du dÃ©sÃ©quilibre des classes
- Visualisations comparatives

### 2 â€” PrÃ©traitement
- Nettoyage des donnÃ©es
- Suppression des doublons
- Traitement des valeurs manquantes
- Normalisation des variables numÃ©riques
- Encodage des variables catÃ©gorielles

### 3 â€” ModÃ©lisation
Plusieurs algorithmes ont Ã©tÃ© testÃ©s :

- XGBoost
- CatBoost
- LightGBM
- SVM
- Random Forest

Chaque modÃ¨le a Ã©tÃ© Ã©valuÃ© :
- avec paramÃ¨tres par dÃ©faut
- aprÃ¨s optimisation par GridSearch

---

## ğŸ“ˆ RÃ©sultats

| ModÃ¨le | Accuracy | F1-score Macro | Observation |
|------|---------|----------------|-------------|
| XGBoost | 0.9871 | **0.8564** | Meilleur modÃ¨le |
| CatBoost | 0.9845 | 0.8388 | TrÃ¨s stable |
| LightGBM | 0.9871 | 0.8274 | Bon compromis |
| SVM | 0.9328 | 0.5747 | Performance moyenne |
| Random Forest | 0.9742 | 0.4242 | Mauvais Ã©quilibre |

---

## ğŸ† ModÃ¨le retenu
Le modÃ¨le **XGBoost optimisÃ©** a Ã©tÃ© sÃ©lectionnÃ© comme solution finale car il offre :

- le meilleur F1-score macro
- un bon Ã©quilibre entre les classes
- une excellente capacitÃ© de gÃ©nÃ©ralisation

---

## ğŸ“‚ Structure du projet
